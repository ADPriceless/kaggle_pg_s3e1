{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6120b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "import xgboost as xgb\n",
    "\n",
    "import kaggle_utils\n",
    "from data_augmentation.combined_attributes_adder import CombinedAttributesAdder\n",
    "from data_augmentation.coords import NearestCluster, DistToCoastLoader, DistToCity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c04681",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = kaggle_utils.read_train_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1b3df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480e3eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Experimentor:\n",
    "    '''A class to make trying different comninations of input preprocessing easier.\n",
    "    User can update a config file to choose how the input is processed'''\n",
    "\n",
    "    def __init__(self):\n",
    "        self.input_data = None\n",
    "        self.model = None\n",
    "        self.cv_results = None\n",
    "        self.prev_cv_results = None\n",
    "        \n",
    "    def _preprocess_input(self):\n",
    "        if self.config['preprocess']['append_sklearn_dataset']:\n",
    "            self._append_additional_data()\n",
    "\n",
    "        X, y = kaggle_utils.split_X_y(self.input_data, 'MedHouseVal')\n",
    "\n",
    "        numeric_pipeline_stages = []\n",
    "\n",
    "        # this reduces performance and increases training time\n",
    "        if self.config['preprocess']['add_attributes']:\n",
    "            numeric_pipeline_stages.append(\n",
    "                ('attr_adder', \n",
    "                 CombinedAttributesAdder(self.config['preprocess']['combined_attrs']))\n",
    "            )\n",
    "\n",
    "        # distance to coastline\n",
    "        if self.config['preprocess']['enable_dist_to_coast']:\n",
    "            numeric_pipeline_stages.append(\n",
    "                ('load_dist_to_coast',\n",
    "                 DistToCoastLoader(\n",
    "                     'data\\\\dist_to_coast.pickle', \n",
    "                     self.config['preprocess']['append_sklearn_dataset']))\n",
    "            )\n",
    "\n",
    "        # distance to major city\n",
    "        if self.config['preprocess']['dist_to_city']['enable']:\n",
    "            city_coords = [np.array(coord) for coord in \\\n",
    "                self.config['preprocess']['dist_to_city']['coords']]\n",
    "            numeric_pipeline_stages.append(\n",
    "                ('dist_to_major_city',\n",
    "                 DistToCity(city_coords))\n",
    "            )\n",
    "\n",
    "        # this makes a negligible improvement (about 0.1%)\n",
    "        if self.config['preprocess']['kmeans']['enable']:\n",
    "            numeric_pipeline_stages.append(\n",
    "                ('nearest_cluster',\n",
    "                 NearestCluster(self.config['preprocess']['kmeans']['n_clusters']))\n",
    "            )\n",
    "\n",
    "        if self.config['preprocess']['do_scale']:\n",
    "            numeric_pipeline_stages.append(('scaler', StandardScaler()))\n",
    "\n",
    "        pipeline = Pipeline(numeric_pipeline_stages)\n",
    "        X_proc = pipeline.fit_transform(X)\n",
    "        \n",
    "        return X_proc, y\n",
    "    \n",
    "    def _append_additional_data(self):\n",
    "        housing = fetch_california_housing()\n",
    "        data = np.concatenate([housing.data, housing.target.reshape([-1, 1])], axis=1)\n",
    "        columns = housing.feature_names + housing.target_names\n",
    "        more_data = pd.DataFrame(data, columns=columns)\n",
    "        self.input_data = pd.concat([self.input_data, more_data], axis=0)\n",
    "\n",
    "    def _set_model_random_state(self):\n",
    "        if 'random_state' in self.model.get_params():\n",
    "            params = {'random_state': self.config['random_state']}\n",
    "            self.model.set_params(**params)\n",
    "            \n",
    "    def _evaluate_cv(self, X, y):\n",
    "        self.prev_cv_results = self.cv_results\n",
    "        k_fold = KFold(\n",
    "            n_splits=self.config['cross_validation']['num_splits'],\n",
    "            shuffle=True,\n",
    "            random_state=self.config['random_state']\n",
    "        )\n",
    "        self.cv_results = cross_validate(\n",
    "            self.model,\n",
    "            X,\n",
    "            y,\n",
    "            cv=k_fold,\n",
    "            scoring=self.config['cross_validation']['scoring'],\n",
    "            n_jobs=-1\n",
    "        )\n",
    "    \n",
    "    def _print_results(self):\n",
    "        rmse = -self.cv_results['test_neg_root_mean_squared_error']\n",
    "        fit_time = self.cv_results['fit_time']\n",
    "        print('CV Results')\n",
    "        print(f'rmse: {rmse.mean():.5f} +/- {rmse.std():.5f}')\n",
    "        print(f'training time: {fit_time.mean():.2f}s +/- {fit_time.std():.2f}s')\n",
    "        if self.prev_cv_results is not None:\n",
    "            rmse = -self.prev_cv_results['test_neg_root_mean_squared_error']\n",
    "            fit_time = self.prev_cv_results['fit_time']\n",
    "            print('-----')\n",
    "            print('Previous CV Results')\n",
    "            print(f'rmse: {rmse.mean():.5f} +/- {rmse.std():.5f}')\n",
    "            print(f'training time: {fit_time.mean():.2f}s +/- {fit_time.std():.2f}s')\n",
    "            \n",
    "    def run(self, model, input_data):\n",
    "        self.model = model\n",
    "\n",
    "        with open('config.json', 'r') as f:\n",
    "            self.config = json.load(f)\n",
    "\n",
    "        self.input_data = input_data\n",
    "        if self.config['preprocess']['do_preproc']:\n",
    "            X_proc, y = self._preprocess_input()    \n",
    "\n",
    "        self._set_model_random_state()\n",
    "\n",
    "        if self.config['cross_validation']['do_cross_val']:\n",
    "            self._evaluate_cv(X_proc, y)\n",
    "            self._print_results()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b67d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "experimentor = Experimentor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac0a174",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GradientBoostingRegressor()\n",
    "# model = xgb.XGBRegressor()\n",
    "experimentor.run(model=model, input_data=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703598a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
